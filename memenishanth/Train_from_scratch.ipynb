{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1057,"status":"ok","timestamp":1610659487042,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"9vOLxNuZlk4m","outputId":"b262ed3a-37a1-4aa1-f551-7c033b07ce3c"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\iamsr\\AppData\\Local\\Temp\\ipykernel_17268\\2084772895.py:17: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n","  demoji.download_codes()\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\losses.py:2940: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]},{"ename":"AttributeError","evalue":"module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\engine\\functional.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\engine\\training.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle_utils\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_api\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m legacy_sm_saving_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;28;01mas\u001b[39;00m saved_model_load\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_context\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m saved_model_save\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_option_scope\n","File \u001b[1;32mc:\\Users\\iamsr\\.conda\\envs\\cuda\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load_context.py:68\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether under a load context.\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_context\u001b[38;5;241m.\u001b[39min_load_context()\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_load_context_function\u001b[49m(in_load_context)\n","\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"]}],"source":["import numpy as np\n","import pandas as pd\n","from transformers import AutoModel, AutoTokenizer\n","import torch.nn as nn\n","import torch\n","import copy\n","from transformers import BertModel, RobertaModel, BertTokenizer, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n","import sklearn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import f1_score \n","from tqdm import tqdm\n","import demoji \n","import random\n","demoji.download_codes() \n","import preprocessor as p\n","import nltk\n","import seaborn as sns\n","import keras\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from keras.layers import SpatialDropout1D\n","from keras.layers import Conv1D\n","from keras.utils import to_categorical\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.model_selection import GridSearchCV\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from sklearn.feature_selection import RFE\n","from keras.callbacks import ModelCheckpoint\n","import re\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED)\n","plt.rcParams['figure.figsize'] = [15, 8]\n","plt.rcParams.update({'font.size': 8})\n","RANDOM_SEED = 42\n","model_path = 'bert-base-multilingual-cased'\n","model_path = 'monsoon-nlp/tamillion'\n","device = torch.device(\"cuda:0\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72QHLh_2T-dA"},"outputs":[],"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value)  \n","    torch.manual_seed(seed_value)  \n","    random.seed(seed_value)\n","    if use_cuda:\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)  \n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","random_seed(RANDOM_SEED, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIOPL_OTrRy4"},"outputs":[],"source":["class Dataset():\n","    def __init__(self, train_data, val_data, test_data):\n","        self.train_data = train_data\n","        self.val_data = val_data\n","        self.test_data = test_data\n","        # self.batch_size = batch_size\n","\n","        self.label_dict = {}\n","        \n","        self.count_dic = {}\n","\n","        # self.trn = Transliterator(source='eng', target='kan', build_lookup=True)\n","\n","        self.train_df = pd.DataFrame(self.process_data(self.train_data))\n","        self.val_df = pd.DataFrame(self.process_data(self.val_data))\n","        self.test_df = pd.DataFrame(self.process_data(self.test_data, test = True))\n","\n","    def is_english(self, s: str) -> bool:\n","        if len(re.findall(u'[\\u0900-\\u097F]', s)) <= 1000:\n","            return True\n","        return False\n","\n","    def process_data(self, data, test = False):\n","        sentences, labels = [], []\n","        print(len(data))\n","        for line in data:\n","            sentence = line.strip().split('\\t')\n","            if not test:\n","                label = sentence.pop()\n","                if label not in self.label_dict:\n","                    self.label_dict[label] = len(self.label_dict)\n","                labels.append(self.label_dict[label])\n","                self.count_dic[label] = self.count_dic.get(label, 0) + 1\n","            sentence = ' '.join(sentence)\n","            # emoji_dict = demoji.findall(sentence)\n","\n","            # # if not self.is_english(sentence):\n","            # #     print(sentence)\n","            # #     sentence = self.trn.transform(sentence)\n","            # #     print(sentence)\n","\n","            # # sentence = self.trn.transform(sentence)\n","            # # print(sentence)\n","\n","            # if len(emoji_dict): \n","            #     for emoji, text in emoji_dict.items():\n","            #         sentence = sentence.replace(emoji, ' '+text+' ')\n","            #         sentence = ' '.join(sentence.split())\n","            sentence = ' '.join(sentence.split())\n","            sentences.append(sentence)\n","            \n","            # labels.append(label)\n","            \n","        if test: return {'input': sentences}\n","        return {'input': sentences, 'label': (labels)}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1360,"status":"ok","timestamp":1610662585483,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"0HBnekZFnnhe","outputId":"8442bf7e-8778-452c-b7ed-c4beb1d4fa95"},"outputs":[],"source":["with open('train.csv', 'r') as f:\n","    train_data = f.readlines()\n","with open('dev.csv', 'r') as f:\n","    val_data = f.readlines()\n","with open('test.csv', 'r') as f:\n","    test_data = f.readlines()\n","data = Dataset(train_data, val_data, test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1144,"status":"ok","timestamp":1610662588148,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"OBmHatXZP_kW","outputId":"80cb0fef-a125-4237-d229-0a5d4bb170f0"},"outputs":[],"source":["data.train_df.input"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1479,"status":"ok","timestamp":1610662590432,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"VnkCJ5xhP5X4","outputId":"57e8539a-47cf-4e20-c50b-a8508531ff28"},"outputs":[],"source":["# The maximum number of words to be used. (most frequent)\n","MAX_NB_WORDS = 64000\n","# Max number of words in each complaint.\n","MAX_SEQUENCE_LENGTH = 128\n","# This is fixed.\n","EMBEDDING_DIM = 100\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=False)\n","tokenizer.fit_on_texts(data.train_df.input)\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1714,"status":"ok","timestamp":1610662592675,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"EDC3Rg7kQGbq","outputId":"166694c0-d45e-459a-fc21-82e9fbb272e0"},"outputs":[],"source":["X_train = tokenizer.texts_to_sequences(data.train_df.input.values)\n","X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n","print('Shape of data tensor:', X_train.shape)\n","\n","X_val = tokenizer.texts_to_sequences(data.val_df.input.values)\n","X_val = pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH)\n","print('Shape of data tensor:', X_val.shape)\n","\n","X_test = tokenizer.texts_to_sequences(data.test_df.input.values)\n","X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n","print('Shape of data tensor:', X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1187,"status":"ok","timestamp":1610662594549,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"0wczaQRm96WJ","outputId":"3dc1f7b3-0bf3-4862-a307-323aae54c8d6"},"outputs":[],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1495,"status":"ok","timestamp":1610662596389,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"k-OGIyrBQVs4","outputId":"ac5d8f1c-83a1-48ab-cd9c-38869410ddf9"},"outputs":[],"source":["Y_train = pd.get_dummies(data.train_df.label).values\n","print('Shape of label tensor:', Y_train.shape)\n","\n","Y_val = pd.get_dummies(data.val_df.label).values\n","print('Shape of label tensor:', Y_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96LsNcZkx0Ih"},"outputs":[],"source":["def get_predicted(preds):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    return pred_flat\n","from sklearn.metrics import f1_score, accuracy_score\n","# def f1(ytrue, ypred):\n","#     return f1_score(get_predicted(np.array(ytrue)), get_predicted(np.array(ypred)), average = 'weighted')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUE9ahFczYq2"},"outputs":[],"source":["from keras import backend as K\n","def f1(true, pred): #shapes (batch, 4)\n","\n","    #for metrics include these two lines, for loss, don't include them\n","    #these are meant to round 'pred' to exactly zeros and ones\n","    #predLabels = K.argmax(pred, axis=-1)\n","    #pred = K.one_hot(predLabels, 4) \n","\n","\n","    ground_positives = K.sum(true, axis=0)       # = TP + FN\n","    pred_positives = K.sum(pred, axis=0)         # = TP + FP\n","    true_positives = K.sum(true * pred, axis=0)  # = TP\n","        #all with shape (4,)\n","\n","    precision = (true_positives + K.epsilon()) / (pred_positives + K.epsilon()) \n","    recall = (true_positives + K.epsilon()) / (ground_positives + K.epsilon()) \n","        #both = 1 if ground_positives == 0 or pred_positives == 0\n","        #shape (4,)\n","\n","    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","        #not sure if this last epsilon is necessary\n","        #matematically not, but maybe to avoid computational instability\n","        #still with shape (4,)\n","\n","    weighted_f1 = f1 * ground_positives / K.sum(ground_positives)\n","    weighted_f1 = K.sum(weighted_f1)\n","\n","\n","    return weighted_f1 #for metrics, return only 'weighted_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJ9qoxcEjdIo"},"outputs":[],"source":["mc = ModelCheckpoint('model_tam_1.h5', monitor='val_f1', mode='max', save_best_only=True)\n","cb_list = mc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jJCi1BrBJgF"},"outputs":[],"source":["from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4956228,"status":"ok","timestamp":1610668345874,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"pvZ3i83rSJIt","outputId":"ef8744a4-5d6c-4a45-82f0-293becb68ab9"},"outputs":[],"source":["model = Sequential()\n","model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n","model.add(SpatialDropout1D(0.2))\n","model.add(layers.Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n","model.add(Dense(6, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\n","history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=4, batch_size=32, callbacks = cb_list)\n","# Final evaluation of the model\n","model_pred_train = model.predict(X_train)\n","model_pred_test = model.predict(X_val)\n","# print(classification_report(test_labels,model_pred_test))\n","print('LSTM Recurrent Neural Network baseline: ' + str(roc_auc_score(Y_train, model_pred_train)))\n","print('LSTM Recurrent Neural Network: ' + str(roc_auc_score(Y_val, model_pred_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1610658693361,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"efSnNzqBu5XS","outputId":"113f7fc3-ac05-488d-e5f1-fe4bf48b985e"},"outputs":[],"source":["model = keras.models.load_model('best_model_tam.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44318,"status":"ok","timestamp":1610662476997,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"Egy-ijmMekdc","outputId":"164306bd-a285-46b1-f7a7-74f0d9f3ac42"},"outputs":[],"source":["\n","model_pred_train = model.predict(X_train)\n","model_pred_test = model.predict(X_val)\n","f1 = f1_score(get_predicted(Y_train), get_predicted(model_pred_train), average = 'weighted')\n","acc = accuracy_score(get_predicted(Y_train), get_predicted(model_pred_train))\n","print(f1, acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41042,"status":"ok","timestamp":1610662476998,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"q33zeNwivrK_","outputId":"0da6a1f9-b092-4bcf-8635-c12f70704da3"},"outputs":[],"source":["f1 = f1_score(get_predicted(Y_val), get_predicted(model_pred_test), average = 'weighted')\n","f1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40866,"status":"ok","timestamp":1610662476998,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"yyw7L_iCvys2","outputId":"de35dc28-e19d-48dc-8bbe-9210165f16cc"},"outputs":[],"source":["acc = accuracy_score(get_predicted(Y_val), get_predicted(model_pred_test))\n","print(f1, acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1nWEeJZfEdE"},"outputs":[],"source":["for x in get_predicted(Y_train): print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1492,"status":"ok","timestamp":1610654429942,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"},"user_tz":-330},"id":"nDTK2oc2fCNH","outputId":"be0e7278-e375-426a-86d3-89b640ee4944"},"outputs":[],"source":["f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__RteAhZSeep"},"outputs":[],"source":["model = Sequential()\n","model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n","model.add(SpatialDropout1D(0.2))\n","model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(6, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(train_features, train_labels, epochs=5, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quTk_hanRRav"},"outputs":[],"source":["_, ypred, ytest = evaluate(data.val_dataloader, model)\n","from sklearn.metrics import confusion_matrix\n","array = confusion_matrix(ytest, ypred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77048,"status":"ok","timestamp":1610025217494,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"},"user_tz":-330},"id":"YZ588U8OTEsh","outputId":"0cbd0e94-a308-4a07-cf27-dbd7377d8d4a"},"outputs":[],"source":["import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","df_cm = pd.DataFrame(array, range(2), range(2))\n","# plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6VHS7N5x6YP"},"outputs":[],"source":["train(data.train_dataloader, data.val_dataloader, model, 'tamil_mal.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gxwu-UTlzJVo"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Train_from_scratch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
